{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Neural Network from Scratch\n",
    "\n",
    "http://jonathanweisberg.org/post/A%20Neural%20Network%20from%20Scratch%20-%20Part%201/\n",
    "\n",
    "\n",
    "In this post we’re going to build a neural network from scratch. We’ll train it to recognize hand-written digits, using the famous MNIST data set.\n",
    "\n",
    "We’ll use just basic Python with NumPy to build our network (no high-level stuff like Keras or TensorFlow). We will dip into scikit-learn, but only to get the MNIST data and to assess our model once its built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (MNIST)\n",
    "## data:  70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "<class 'numpy.ndarray'>\n",
      "(70000, 784)\n",
      "<class 'numpy.ndarray'>\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(type(mnist))\n",
    "#print(mnist.shape)\n",
    "\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "\n",
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We’ll normalize the data to keep our gradients manageable:\n",
    "\n",
    "X = X / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 70000)\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 70000, 10)\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 70000)\n"
     ]
    }
   ],
   "source": [
    "# Then we’ll one-hot encode MNIST’s labels, to get a 10 x 70,000 array.\n",
    "\n",
    "digits = 10\n",
    "examples = y.shape[0]\n",
    "\n",
    "print(y.shape)\n",
    "y = y.reshape(1, examples)\n",
    "print(type(y))\n",
    "print(y.shape)\n",
    "\n",
    "Y_new = np.eye(digits)[y.astype('int32')]\n",
    "print(type(Y_new))\n",
    "print(Y_new.shape)\n",
    "\n",
    "Y_new = Y_new.T.reshape(digits, examples)\n",
    "print(type(Y_new))\n",
    "print(Y_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1, 70000)\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 70000)\n"
     ]
    }
   ],
   "source": [
    "print(type(y))\n",
    "print(y.shape)\n",
    "\n",
    "print(type(Y_new))\n",
    "print(Y_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we re-split, re-shape, and re-shuffle our training set:\n",
    "\n",
    "m = 60000\n",
    "m_test = X.shape[0] - m\n",
    "\n",
    "X_train, X_test = X[:m].T, X[m:].T\n",
    "Y_train, Y_test = Y_new[:,:m], Y_new[:,m:]\n",
    "\n",
    "shuffle_index = np.random.permutation(m)\n",
    "X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(784, 60000)\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 60000)\n",
      "<class 'numpy.ndarray'>\n",
      "(784, 10000)\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "\n",
    "print(type(Y_train))\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(type(X_test))\n",
    "print(X_test.shape)\n",
    "\n",
    "print(type(Y_test))\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(784, 60000)\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 60000)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "\n",
    "print(type(Y_train))\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick check that things are as they should be:\n",
    "\n",
    "i = 12\n",
    "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "Y_train[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So let’s define:\n",
    "\n",
    "def compute_multiclass_loss(Y, Y_hat):\n",
    "\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1/m) * L_sum\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost:  6.282446069514026\n",
      "Epoch 100 cost:  0.7780882828822755\n",
      "Epoch 200 cost:  0.5852474032349623\n",
      "Epoch 300 cost:  0.5016984625378214\n",
      "Epoch 400 cost:  0.4519854553590349\n",
      "Epoch 500 cost:  0.41755708754491955\n",
      "Epoch 600 cost:  0.3915522714486615\n",
      "Epoch 700 cost:  0.37082507864675823\n",
      "Epoch 800 cost:  0.3536663585473053\n",
      "Epoch 900 cost:  0.33907321709044536\n",
      "Epoch 1000 cost:  0.3264064309170943\n",
      "Epoch 1100 cost:  0.3152357827367462\n",
      "Epoch 1200 cost:  0.3052702656633586\n",
      "Epoch 1300 cost:  0.29629945726494594\n",
      "Epoch 1400 cost:  0.2881573102618223\n",
      "Epoch 1500 cost:  0.28071292410665727\n",
      "Epoch 1600 cost:  0.2738644853149811\n",
      "Epoch 1700 cost:  0.267531458614318\n",
      "Epoch 1800 cost:  0.261648981923142\n",
      "Epoch 1900 cost:  0.25616357613941637\n",
      "Final cost: 0.2510795058585822\n"
     ]
    }
   ],
   "source": [
    "# 4.5 Build & Train\n",
    "\n",
    "n_x = X_train.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 1\n",
    "\n",
    "W1 = np.random.randn(n_h, n_x)\n",
    "b1 = np.zeros((n_h, 1))\n",
    "W2 = np.random.randn(digits, n_h)\n",
    "b2 = np.zeros((digits, 1))\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "for i in range(2000):\n",
    "\n",
    "    Z1 = np.matmul(W1,X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.matmul(W2,A1) + b2\n",
    "    A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "    cost = compute_multiclass_loss(Y, A2)\n",
    "\n",
    "    dZ2 = A2-Y\n",
    "    dW2 = (1./m) * np.matmul(dZ2, A1.T)\n",
    "    db2 = (1./m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.matmul(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "    dW1 = (1./m) * np.matmul(dZ1, X.T)\n",
    "    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Epoch\", i, \"cost: \", cost)\n",
    "\n",
    "print(\"Final cost:\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 943    0    7    2    2   13    8    3    8    5]\n",
      " [   0 1110    4    1    0    1    1    8    5    3]\n",
      " [   2    3  944   19    9    5   10   32   15    0]\n",
      " [   3    3   14  917    2   40    4    6   30   14]\n",
      " [   1    1    9    1  900    5   11    8   18   36]\n",
      " [  11    1    3   24    0  780   16    4   24   10]\n",
      " [  13    3    9    4   17   11  896    2   13    1]\n",
      " [   1    3   15   11    6    7    4  930    9   24]\n",
      " [   5   11   21   23    7   24    8    4  840   14]\n",
      " [   1    0    6    8   39    6    0   31   12  902]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.95      0.96       991\n",
      "          1       0.98      0.98      0.98      1133\n",
      "          2       0.91      0.91      0.91      1039\n",
      "          3       0.91      0.89      0.90      1033\n",
      "          4       0.92      0.91      0.91       990\n",
      "          5       0.87      0.89      0.88       873\n",
      "          6       0.94      0.92      0.93       969\n",
      "          7       0.90      0.92      0.91      1010\n",
      "          8       0.86      0.88      0.87       957\n",
      "          9       0.89      0.90      0.90      1005\n",
      "\n",
      "avg / total       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let’s see how we did:\n",
    "\n",
    "Z1 = np.matmul(W1, X_test) + b1\n",
    "A1 = sigmoid(Z1)\n",
    "Z2 = np.matmul(W2, A1) + b2\n",
    "A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "predictions = np.argmax(A2, axis=0)\n",
    "labels = np.argmax(Y_test, axis=0)\n",
    "\n",
    "index = 0\n",
    "misclassifiedIndexes = []\n",
    "for label, predict in zip(labels, predictions):\n",
    "    if label != predict: \n",
    "        misclassifiedIndexes.append(index)\n",
    "    index +=1\n",
    "\n",
    "print(confusion_matrix(predictions, labels))\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "838\n"
     ]
    }
   ],
   "source": [
    "print(len(misclassifiedIndexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.9162\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:  \", 1 - (len(misclassifiedIndexes)/10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
