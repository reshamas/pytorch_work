{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Neural Network from Scratch\n",
    "\n",
    "http://jonathanweisberg.org/post/A%20Neural%20Network%20from%20Scratch%20-%20Part%201/\n",
    "\n",
    "\n",
    "In this post we’re going to build a neural network from scratch. We’ll train it to recognize hand-written digits, using the famous MNIST data set.\n",
    "\n",
    "We’ll use just basic Python with NumPy to build our network (no high-level stuff like Keras or TensorFlow). We will dip into scikit-learn, but only to get the MNIST data and to assess our model once its built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (Fashion MNIST)\n",
    "## data:  70000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/reshamashaikh/ds/my_repos/pytorch_work/data_fashion/'\n",
    "#path = '/Users/reshamashaikh/ds/my_repos/fashion_mnist/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 171304\r\n",
      "drwxr-xr-x  22 reshamashaikh  staff       704 Sep  9 17:33 \u001b[1m\u001b[36m..\u001b[m\u001b[m\r\n",
      "-rw-r--r--@  1 reshamashaikh  staff      6148 Aug 31 22:59 .DS_Store\r\n",
      "drwxr-xr-x  11 reshamashaikh  staff       352 Aug 31 22:59 \u001b[1m\u001b[36m.\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 reshamashaikh  staff     10008 Aug 31 22:59 t10k-labels-idx1-ubyte\r\n",
      "-rw-r--r--   1 reshamashaikh  staff     60008 Aug 31 22:58 train-labels-idx1-ubyte\r\n",
      "-rw-r--r--   1 reshamashaikh  staff  47040016 Aug 31 22:58 train-images-idx3-ubyte\r\n",
      "-rw-r--r--   1 reshamashaikh  staff   7840016 Aug 31 22:58 t10k-images-idx3-ubyte\r\n",
      "-rw-r--r--@  1 reshamashaikh  staff      5148 Aug 31  2017 t10k-labels-idx1-ubyte.gz\r\n",
      "-rw-r--r--@  1 reshamashaikh  staff   4422102 Aug 31  2017 t10k-images-idx3-ubyte.gz\r\n",
      "-rw-r--r--@  1 reshamashaikh  staff     29515 Aug 31  2017 train-labels-idx1-ubyte.gz\r\n",
      "-rw-r--r--@  1 reshamashaikh  staff  26421880 Aug 31  2017 train-images-idx3-ubyte.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alt {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = load_mnist(path, kind='train')\n",
    "X_test, Y_test = load_mnist(path, kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(60000, 784)\n",
      "<class 'numpy.ndarray'>\n",
      "(60000,)\n",
      "<class 'numpy.ndarray'>\n",
      "(10000, 784)\n",
      "<class 'numpy.ndarray'>\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "\n",
    "print(type(Y_train))\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(type(X_test))\n",
    "print(X_test.shape)\n",
    "\n",
    "print(type(Y_test))\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_mldata\n",
    "\n",
    "# mnist = fetch_mldata('MNIST original')\n",
    "# X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We’ll normalize the data to keep our gradients manageable:\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(784, 60000)\n",
      "<class 'numpy.ndarray'>\n",
      "(784, 10000)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.transpose(X_train)\n",
    "X_test = np.transpose(X_test)\n",
    "\n",
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "\n",
    "print(type(X_test))\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "(60000,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 60000)\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 60000, 10)\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 60000)\n",
      "--------------------\n",
      "(10000,)\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 10000)\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 10000, 10)\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Then we’ll one-hot encode MNIST’s labels, to get a 10 x 70,000 array.\n",
    "digits = 10\n",
    "m = 60000\n",
    "\n",
    "def encode_labels(y, logp):\n",
    "    #digits = 10\n",
    "    examples = y.shape[0]\n",
    "\n",
    "    print('-'*20)\n",
    "    print(y.shape)\n",
    "    y = y.reshape(1, examples)\n",
    "    if logp == 1:\n",
    "        print(type(y))\n",
    "        print(y.shape)\n",
    "\n",
    "    Y_new = np.eye(digits)[y.astype('int32')]\n",
    "    if logp == 1:\n",
    "        print(type(Y_new))\n",
    "        print(Y_new.shape)\n",
    "\n",
    "    Y_new = Y_new.T.reshape(digits, examples)\n",
    "    if logp == 1:\n",
    "        print(type(Y_new))\n",
    "        print(Y_new.shape)\n",
    "        \n",
    "    return Y_new\n",
    "\n",
    "Y_train = encode_labels(Y_train, 1)\n",
    "Y_test = encode_labels(Y_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(784, 60000)\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 60000)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "\n",
    "print(type(Y_train))\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick check that things are as they should be:\n",
    "\n",
    "i = 12\n",
    "plt.imshow(X_train[:,i].reshape(28,28), cmap = matplotlib.cm.binary)\n",
    "plt.axis(\"on\")\n",
    "plt.show()\n",
    "Y_train[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So let’s define:\n",
    "\n",
    "def compute_multiclass_loss(Y, Y_hat):\n",
    "\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1/m) * L_sum\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 cost:  6.610702254862646\n",
      "Epoch 100 cost:  0.9620180315785246\n",
      "Epoch 200 cost:  0.8402263067690293\n",
      "Epoch 300 cost:  0.7811708527971\n",
      "Epoch 400 cost:  0.7274272068968991\n",
      "Epoch 500 cost:  0.6830446177948594\n",
      "Epoch 600 cost:  0.6458801818990421\n",
      "Epoch 700 cost:  0.6167941729027928\n",
      "Epoch 800 cost:  0.5944074476825082\n",
      "Epoch 900 cost:  0.5766117413261572\n",
      "Epoch 1000 cost:  0.5610676746377082\n",
      "Epoch 1100 cost:  0.5477173361745385\n",
      "Epoch 1200 cost:  0.5357986955550329\n",
      "Epoch 1300 cost:  0.5250015240908327\n",
      "Epoch 1400 cost:  0.5151646163432007\n",
      "Epoch 1500 cost:  0.506175718518084\n",
      "Epoch 1600 cost:  0.4979345955512209\n",
      "Epoch 1700 cost:  0.49034768891299363\n",
      "Epoch 1800 cost:  0.4833300307074315\n",
      "Epoch 1900 cost:  0.47680751291267565\n",
      "Final cost: 0.4644229896951908\n"
     ]
    }
   ],
   "source": [
    "# 4.5 Build & Train\n",
    "\n",
    "n_x = X_train.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 1\n",
    "\n",
    "W1 = np.random.randn(n_h, n_x)\n",
    "b1 = np.zeros((n_h, 1))\n",
    "W2 = np.random.randn(digits, n_h)\n",
    "b2 = np.zeros((digits, 1))\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "for i in range(2000):\n",
    "\n",
    "    Z1 = np.matmul(W1,X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.matmul(W2,A1) + b2\n",
    "    A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "    cost = compute_multiclass_loss(Y, A2)\n",
    "\n",
    "    dZ2 = A2-Y\n",
    "    dW2 = (1./m) * np.matmul(dZ2, A1.T)\n",
    "    db2 = (1./m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dA1 = np.matmul(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "    dW1 = (1./m) * np.matmul(dZ1, X.T)\n",
    "    db1 = (1./m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Epoch\", i, \"cost: \", cost)\n",
    "\n",
    "print(\"Final cost:\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[863   7  30  53   1   0 263   0   8   1]\n",
      " [  5 952   1  24   2   1   0   0   2   0]\n",
      " [ 22   5 751  21 149   0 167   0  24   0]\n",
      " [ 56  28   8 841  31   0  50   0   5   0]\n",
      " [ 10   3 148  49 786   0 157   0  11   0]\n",
      " [  3   0   2   1   2 899   0  33   6  19]\n",
      " [ 24   3  46   9  23   0 328   0   4   0]\n",
      " [  1   0   0   0   0  57   0 909  12  46]\n",
      " [ 16   2  13   2   6  10  35   2 928   5]\n",
      " [  0   0   1   0   0  33   0  56   0 929]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.70      0.78      1226\n",
      "          1       0.95      0.96      0.96       987\n",
      "          2       0.75      0.66      0.70      1139\n",
      "          3       0.84      0.83      0.83      1019\n",
      "          4       0.79      0.68      0.73      1164\n",
      "          5       0.90      0.93      0.92       965\n",
      "          6       0.33      0.75      0.46       437\n",
      "          7       0.91      0.89      0.90      1025\n",
      "          8       0.93      0.91      0.92      1019\n",
      "          9       0.93      0.91      0.92      1019\n",
      "\n",
      "avg / total       0.85      0.82      0.83     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let’s see how we did:\n",
    "\n",
    "Z1 = np.matmul(W1, X_test) + b1\n",
    "A1 = sigmoid(Z1)\n",
    "Z2 = np.matmul(W2, A1) + b2\n",
    "A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "predictions = np.argmax(A2, axis=0)\n",
    "labels = np.argmax(Y_test, axis=0)\n",
    "\n",
    "index = 0\n",
    "misclassifiedIndexes = []\n",
    "for label, predict in zip(labels, predictions):\n",
    "    if label != predict: \n",
    "        misclassifiedIndexes.append(index)\n",
    "    index +=1\n",
    "\n",
    "print(confusion_matrix(predictions, labels))\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1814\n"
     ]
    }
   ],
   "source": [
    "print(len(misclassifiedIndexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.8186\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:  \", 1 - (len(misclassifiedIndexes)/10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
